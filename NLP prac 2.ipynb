{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cacefaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prac 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f602448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prac 2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1a36f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "#nltk.download('brown')\n",
    "brown.categories()\n",
    "brown.fileids()\n",
    "brown.fileids()\n",
    "brown.words()\n",
    "brown.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56dd003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prac 2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0b5e9a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'this', 'is', 'Practical', 'no', '2']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from nltk.corpus.reader import WordListCorpusReader\n",
    "path = os.path.expanduser('~/natural_language_toolkit_data')\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "os.path.exists(path)\n",
    "data = WordListCorpusReader('.',['wordfile.txt'])\n",
    "print(data.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d41e41df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prac2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "70e4d583",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package udhr to\n",
      "[nltk_data]     C:\\Users\\anike\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package udhr is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['news', 'romance']\n",
      "        1789 1793 1797 1805 1813 1817 1821 1833 1837 1841 1849 1853 1857 1861 1865 1877 1881 1885 1889 1893 1897 1901 1909 1917 1921 1925 1929 1933 1937 1941 1945 1949 1953 1957 1961 1965 1969 1973 1977 1981 1985 1989 1993 1997 2001 2005 2009 2013 2017 2021 \n",
      "america    2    3   11   12   13   14   16   18   20   27   29   31   34   36   37   38   40   44   50   59   68   75   87   91  115  126  138  140  145  157  159  163  169  176  183  193  203  226  231  247  268  279  312  343  363  393  408  427  462  502 \n",
      "           0    1    2    3    4    5    6    7    8    9 \n",
      "English    0  185  525  883  997 1166 1283 1440 1558 1638 \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "#nltk.download('inaugural')\n",
    "nltk.download('udhr')\n",
    "from nltk.corpus import inaugural\n",
    "from nltk.corpus import udhr\n",
    "genre_word= [(genre,word)\n",
    "            for genre in ['news','romance']\n",
    "            for word in brown.words(categories=genre)]\n",
    "cfd = nltk.ConditionalFreqDist(genre_word)\n",
    "print(cfd.conditions())\n",
    "augural_words= [(target ,fileid[:4])\n",
    "                 for fileid in inaugural.fileids()\n",
    "                  for w in inaugural.words(fileid)\n",
    "                  for target in ['america','citizen']\n",
    "                  if w.lower().startswith(target)]\n",
    "cfd1 = nltk.ConditionalFreqDist(inaugural_words)\n",
    "cfd1.conditions()\n",
    "cfd1.tabulate(conditions=['america'], cumulative=True)\n",
    "languages=['English']\n",
    "udhr_words=[(lang, len(word))\n",
    "        for lang in languages\n",
    "        for word in udhr.words(lang + '-Latin1')]\n",
    "cfd2 = nltk.ConditionalFreqDist(udhr_words)\n",
    "cfd2.tabulate(conditions=['English'],samples=range(10), cumulative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df8be756",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prac 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "30aceef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a program to find the most frequent noun tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d6c9a2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\anike\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('world', 346),\n",
       " ('time', 250),\n",
       " ('way', 236),\n",
       " ('end', 206),\n",
       " ('fact', 194),\n",
       " ('state', 190),\n",
       " ('man', 176),\n",
       " ('door', 172),\n",
       " ('house', 152),\n",
       " ('city', 127)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "nltk.download('universal_tagset')\n",
    "nounlist= nltk.FreqDist(w2 for ((w1,t1),(w2,t2)) in\n",
    "                       nltk.bigrams(brown.tagged_words(tagset=\"universal\"))\n",
    "                        if w1.lower() == \"the\" and t2 == \"NOUN\")\n",
    "nounlist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "97aba2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prac 2e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cebf0119",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map Words to Properties Using Python Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "80a2f08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'brand': 'Ford', 'model': 'Mustang', 'year': 1964}\n",
      "Ford\n",
      "length: 3\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "#creating and printing a dictionay by mapping word with its properties\n",
    "thisdict = {\n",
    "  \"brand\": \"Ford\",\n",
    "  \"model\": \"Mustang\",\n",
    "  \"year\": 1964\n",
    "}\n",
    "print(thisdict)\n",
    "print(thisdict[\"brand\"])\n",
    "print('length:', len(thisdict))\n",
    "print(type(thisdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0eddda57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prac 2f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "125e9e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Study DefaultTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6489a48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'NN'),\n",
       " ('do', 'NN'),\n",
       " ('not', 'NN'),\n",
       " ('like', 'NN'),\n",
       " ('green', 'NN'),\n",
       " ('eggs', 'NN'),\n",
       " ('and', 'NN'),\n",
       " ('ham', 'NN'),\n",
       " (',', 'NN'),\n",
       " ('I', 'NN'),\n",
       " ('do', 'NN'),\n",
       " ('not', 'NN'),\n",
       " ('like', 'NN'),\n",
       " ('them', 'NN'),\n",
       " ('Sam', 'NN'),\n",
       " ('I', 'NN'),\n",
       " ('am', 'NN'),\n",
       " ('!', 'NN')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "import nltk\n",
    "tag = [ tag for (word,tag) in brown.tagged_words(categories='news')]\n",
    "nltk.FreqDist(tag).max()\n",
    "raw = 'I do not like green eggs and ham, I do not like them Sam I am!'\n",
    "token = nltk.word_tokenize(raw)\n",
    "default_tagger = nltk.DefaultTagger('NN')\n",
    "default_tagger.tag(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "feb76764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unigram tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ebf5f506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Displaying the tags from brown sents : \n",
      " [('Various', 'JJ'), ('of', 'IN'), ('the', 'AT'), ('apartments', 'NNS'), ('are', 'BER'), ('of', 'IN'), ('the', 'AT'), ('terrace', 'NN'), ('type', 'NN'), (',', ','), ('being', 'BEG'), ('on', 'IN'), ('the', 'AT'), ('ground', 'NN'), ('floor', 'NN'), ('so', 'QL'), ('that', 'CS'), ('entrance', 'NN'), ('is', 'BEZ'), ('direct', 'JJ'), ('.', '.')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anike\\AppData\\Local\\Temp\\ipykernel_17652\\25632951.py:11: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  evaluation = unigram_tagger.evaluate(brown_tagged_sents)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation of brown tagged sents :  0.9349006503968017\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download('brown')\n",
    "# nltk.download('punkt')\n",
    "from nltk.corpus import brown\n",
    "from nltk import UnigramTagger\n",
    "brown_tagged_sents = brown.tagged_sents(categories = 'news')\n",
    "brown_sents = brown.sents(categories = 'news')\n",
    "unigram_tagger = nltk.UnigramTagger(brown_tagged_sents)\n",
    "tags = unigram_tagger.tag(brown_sents[2007])\n",
    "print(\"\\nDisplaying the tags from brown sents : \\n\", tags)\n",
    "evaluation = unigram_tagger.evaluate(brown_tagged_sents)\n",
    "print(\"\\nEvaluation of brown tagged sents : \", evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "97663aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regular Expression Tagger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3f0ad186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('``', 'NN'),\n",
       " ('Only', 'NN'),\n",
       " ('a', 'NN'),\n",
       " ('relative', 'NN'),\n",
       " ('handful', 'NN'),\n",
       " ('of', 'NN'),\n",
       " ('such', 'NN'),\n",
       " ('reports', 'NNS'),\n",
       " ('was', 'NNS'),\n",
       " ('received', 'VBD'),\n",
       " (\"''\", 'NN'),\n",
       " (',', 'NN'),\n",
       " ('the', 'NN'),\n",
       " ('jury', 'NN'),\n",
       " ('said', 'NN'),\n",
       " (',', 'NN'),\n",
       " ('``', 'NN'),\n",
       " ('considering', 'VBG'),\n",
       " ('the', 'NN'),\n",
       " ('widespread', 'NN'),\n",
       " ('interest', 'NN'),\n",
       " ('in', 'NN'),\n",
       " ('the', 'NN'),\n",
       " ('election', 'NN'),\n",
       " (',', 'NN'),\n",
       " ('the', 'NN'),\n",
       " ('number', 'NN'),\n",
       " ('of', 'NN'),\n",
       " ('voters', 'NNS'),\n",
       " ('and', 'NN'),\n",
       " ('the', 'NN'),\n",
       " ('size', 'NN'),\n",
       " ('of', 'NN'),\n",
       " ('this', 'NNS'),\n",
       " ('city', 'NN'),\n",
       " (\"''\", 'NN'),\n",
       " ('.', 'NN')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download('brown')\n",
    "# nltk.download('punkt')\n",
    "from nltk.corpus import brown\n",
    "from nltk import word_tokenize\n",
    "from nltk import RegexpTagger\n",
    "brown_sents = brown.sents(categories = 'news')\n",
    "brown_tagged_sents = brown.tagged_sents(categories = 'news')\n",
    "patterns = [\n",
    "(r'.*ing$', 'VBG'), # gerunds\n",
    "(r'.*ed$', 'VBD'), # simple past\n",
    "(r'.*es$', 'VBZ'), # 3rd singular present\n",
    "(r'.*ould$', 'MD'), # modals\n",
    "(r'.*\\'s$', 'NN$'), # possessive nouns\n",
    "(r'.*s$', 'NNS'), # plural nouns\n",
    "(r'^-?[0-9]+(\\.[0-9]+)?$', 'CD'), # cardinal numbers\n",
    "(r'.*', 'NN') # nouns (default)\n",
    "]\n",
    "regexp_tagger = nltk.RegexpTagger(patterns)\n",
    "regexp_tagger.tag(brown_sents[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a465d8df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
